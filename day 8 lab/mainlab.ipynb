{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from helpers import helpers_formulate_lanes as formulate_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainfunc(greyimg,low_th,high_th,minlinelin,maxlinegap,orgimg):\n",
    "    aftcanny=cannyimg(greyimg,low_th,high_th)\n",
    "    aftmask=maskROI(aftcanny)\n",
    "    afthoughline=hough_lines(aftcanny,minlinelin,maxlinegap)\n",
    "    aftform=formulate_lanes(afthoughline,aftmask)\n",
    "    lanes_img = draw_lines(aftform, orgimg)\n",
    "    return cv2.addWeighted(orgimg, 0.9, lanes_img, 1, 0)\n",
    "def draw_lines(lines, masked_edges):\n",
    "  color = [243, 105, 14]\n",
    "  thickness = 12\n",
    "  lines_image = np.zeros((masked_edges.shape[0], masked_edges.shape[1], 3), dtype=np.uint8)\n",
    "  for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "      cv2.line(lines_image, (x1, y1), (x2, y2), color, thickness)\n",
    "  return(lines_image)\n",
    "def hough_lines(img,min_line_len,max_line_gap):\n",
    "  RHO = 1                 # try: 1 - 4 (0.5 increments)  \n",
    "  THETA = np.pi/180       # Usually this is Ok\n",
    "  MIN_VOTES = 10          # try: 10 - 50                  # Typical: 30\n",
    "  #MIN_LINE_LEN = 5 \n",
    "  #MAX_LINE_GAP = 50 \n",
    "  lines = cv2.HoughLinesP(img, RHO, THETA, MIN_VOTES, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "  return lines\n",
    "def cannyimg(img,low_th,high_th):\n",
    "  return cv2.Canny(cv2.GaussianBlur(img, (7,7), 0), low_th, high_th)\n",
    "def maskROI(img):\n",
    "  mask = np.zeros_like(img)\n",
    "  if len(img.shape) > 2:\n",
    "    channel_count = img.shape[2]\n",
    "    ignore_mask_color = (255,) * channel_count\n",
    "  else:\n",
    "    ignore_mask_color = 255\n",
    "  imshape = img.shape        \n",
    "  vertices = np.array([\n",
    "    [\n",
    "      ((1/6*imshape[1]), imshape[0]),\n",
    "      ((5/12*imshape[1]), (3/5*imshape[0])),\n",
    "      ((7/12*imshape[1]), (3/5*imshape[0])),\n",
    "      ((9/10*imshape[1]), imshape[0])\n",
    "    ]], dtype=np.int32)\n",
    "  cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "  masked_edges = cv2.bitwise_and(img, mask)\n",
    "  return(masked_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 Make Trackbar for the following images to tune the parameters of canny detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2581: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ba82086ef782>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mlow_th1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lowth1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mhigh_th1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"highth1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mlow_th2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetTrackbarPos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lowth2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2581: error: (-27:Null pointer) NULL window: 'image' in function 'cvGetTrackbarPos'\n"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"image\")\n",
    "def fadya(x):\n",
    "    pass\n",
    "\n",
    "img1=cv2.imread(\"solidWhiteCurve.jpg\")\n",
    "greyimg1=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "img2=cv2.imread(\"solidYellowCurve2.jpg\")\n",
    "greyimg2=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "cv2.createTrackbar(\"lowth1\",\"image\",1,500,fadya)\n",
    "cv2.createTrackbar(\"highth1\",\"image\",1,500,fadya)\n",
    "cv2.createTrackbar(\"lowth2\",\"image\",1,500,fadya)\n",
    "cv2.createTrackbar(\"highth2\",\"image\",1,500,fadya)\n",
    "\n",
    "while(True):\n",
    "    low_th1 = cv2.getTrackbarPos(\"lowth1\",\"image\")\n",
    "    high_th1 = cv2.getTrackbarPos(\"highth1\",\"image\")\n",
    "    low_th2 = cv2.getTrackbarPos(\"lowth2\",\"image\")\n",
    "    high_th2 = cv2.getTrackbarPos(\"highth2\",\"image\")\n",
    "    cv2.imshow(\"image1\",cannyimg(greyimg1,low_th1,high_th1))\n",
    "    cv2.imshow(\"image2\",cannyimg(greyimg1,low_th2,high_th2))\n",
    "    key=cv2.waitKey(1)\n",
    "    if(key==ord('q')):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "#118,169 best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 The out of question 1 make it as input for question 2 after make region of interest then make trackbar for houghlines parameters (threshold ,min_line_length max_line_gap and then draw 2 line on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ws\\opencv\\day 8 lab\\helpers.py:68: RuntimeWarning: divide by zero encountered in int_scalars\n",
      "  slope = (y2-y1)/(x2-x1)\n",
      "d:\\ws\\opencv\\day 8 lab\\helpers.py:69: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  intercept = y2 - (slope*x2)\n"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"image\")\n",
    "def fadya(x):\n",
    "    pass\n",
    "\n",
    "img1=cv2.imread(\"solidWhiteCurve.jpg\")\n",
    "greyimg1=cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "img2=cv2.imread(\"solidYellowCurve2.jpg\")\n",
    "greyimg2=cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "cv2.createTrackbar(\"lowth1\",\"image\",1,500,fadya)\n",
    "cv2.createTrackbar(\"highth1\",\"image\",1,500,fadya)\n",
    "cv2.createTrackbar(\"lowth2\",\"image\",1,500,fadya)\n",
    "cv2.createTrackbar(\"highth2\",\"image\",1,500,fadya)\n",
    "\n",
    "cv2.createTrackbar(\"minlinelin1\",\"image\",1,100,fadya)\n",
    "cv2.createTrackbar(\"maxlinegap1\",\"image\",1,100,fadya)\n",
    "cv2.createTrackbar(\"minlinelin2\",\"image\",1,100,fadya)\n",
    "cv2.createTrackbar(\"maxlinegap2\",\"image\",1,100,fadya)\n",
    "\n",
    "while(True):\n",
    "    low_th1 = cv2.getTrackbarPos(\"lowth1\",\"image\")\n",
    "    high_th1 = cv2.getTrackbarPos(\"highth1\",\"image\")\n",
    "    low_th2 = cv2.getTrackbarPos(\"lowth2\",\"image\")\n",
    "    high_th2 = cv2.getTrackbarPos(\"highth2\",\"image\")\n",
    "    minlinelin1 = cv2.getTrackbarPos(\"minlinelin1\",\"image\")\n",
    "    maxlinegap1 = cv2.getTrackbarPos(\"maxlinegap1\",\"image\")\n",
    "    minlinelin2 = cv2.getTrackbarPos(\"minlinelin2\",\"image\")\n",
    "    maxlinegap2 = cv2.getTrackbarPos(\"maxlinegap2\",\"image\")\n",
    "    final_img1=mainfunc(greyimg1,low_th1,high_th1,minlinelin1,maxlinegap1,img1)\n",
    "    final_img2=mainfunc(greyimg2,low_th2,high_th2,minlinelin2,maxlinegap2,img2)\n",
    "\n",
    "    cv2.imshow(\"image1\",final_img1)\n",
    "    cv2.imshow(\"image2\",final_img2)\n",
    "    key=cv2.waitKey(1)\n",
    "    if(key==ord('q')):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3 read the following video and apply lane line detection on it then show output using opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(\"./solidWhiteRight.mp4\")\n",
    "while(cap.isOpened()):\n",
    "    stat,frame=cap.read()\n",
    "    if(stat==True):\n",
    "        cv2.imshow(\"window\",mainfunc(cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY),52,123,40,0,frame))\n",
    "        key=cv2.waitKey(int(1000/30))\n",
    "        if(key==ord('q')):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    #lowth:52 highth:127 minlen:30\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ba10947d4943caf114b0b0bf83fd9f73372e3215e53e488ddab7d5a1f17815b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
